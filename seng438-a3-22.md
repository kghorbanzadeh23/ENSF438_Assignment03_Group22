**SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report #3 – Code Coverage, Adequacy Criteria and Test Case Correlation**

| Group #22      |
| -------------- |
| Student Names: |
|  Isabelle      |
|  Kamand        |
|  Spiro         |
|  Dylan         |

# 1 Introduction

This lab was built using our previous assignment as a foundation. We used our existing test cases for assignment 2 and expanded our unit tests for JFreeChart (the SUT) by using our chosen coverage tool EclEmma to improve our coverage. To improve test effectiveness, we used white-box testing techniques, including control flow coverage (line, branch, and method metrics) and data flow coverage (DU pair coverage). We constructed data flow graphs and identified def-use pairs to enhance our understanding of variable usage and improve test case design.

# 2 Manual data-flow coverage calculations for X and Y methods

## Method 1: DataUtilities.calculateColumnTotal
![alt text](media/image.png)

### Data flow graph

![alt text](media/image-3.png)

### Def-use sets per statement

| Line | Code                                                                 | DU (Definition-Use) |
|------|----------------------------------------------------------------------|---------------------|
| 1    | public static double calculateColumnTotal(Values2D data, int column) |def={data,column} c-use={} p-use={} |
| 2    | ParamChecks.nullNotPermitted(data, "data");                          |def={} c-use={data} p-use={} |
| 3    | double total = 0.0;                                                  |def={total} c-use={} p-use={} |
| 4    | int rowCount = data.getRowCount();                                   |def={rowCount} c-use={data} p-use={} |
| 5    | for (int r = 0; r < rowCount; r++)                                   |def={r} c-use={r} p-use={r, rowCount} |
| 6    | Number n = data.getValue(r, column);                                 |def={n} c-use={data,r,column} p-use={} |
| 7    | if (n != null)                                                       |def={} c-use={} p-use={n} |
| 8    | total += n.doubleValue();                                            |def={total} c-use={total,n} p-use={} |
| 9    | for (int r2 = 0; r2 > rowCount; r2++)                                |def={r2} c-use={r2} p-use={r2,rowCount} |
| 10   | Number n = data.getValue(r2, column);                                |def={n} c-use={data,r2,column} p-use={} |
| 11   | if (n != null)                                                       |def={} c-use={} p-use={n} |
| 12   | total += n.doubleValue();                                            |def={total} c-use={total,n} p-use={} |
| 13   | return total;                                                        |def={} c-use={total} p-use={} |


### All DU-pairs per variable
                                
| Variable | Def Line | Use Line          | DU Pair                                      |
|----------|----------|-------------------|----------------------------------------------|
| data     | 1        | 2, 4, 6, 10       | {1,2}, {1,4}, {1,6}, {1,10}                  |
| column   | 1        | 6, 10             | {1,6}, {1,10}                                |
| total    | 3, 8, 12 | 8, 12, 13         | {3,8}, {3,12}, {3,13}, {8,8}, {8,12}, {8,13}, {12,8}, {12,12}, {12,13} |
| rowCount | 4        | 5, 9              | {4,5}, {4,9}                                 |
| r        | 5        | 5, 6              | {5,5}, {5,6}                                 |
| n        | 6, 10    | 7, 8, 11, 12      | {6,7}, {6,8}, {6,11}, {6,12}, {10,7}, {10,8}, {10,11}, {10,12} |
| r2       | 9        | 11, 12            | {9,11}, {9,12}                               |


### Each test case show which pairs are covered

    Cover pairs: {1,2}, {1,4}, {1,6}, {3,8}, {3,13}, {8,8}, {8,13}, {4,5}, {5,5}, {5,6}, {6,7},{6,8}
    // Test contains multiple rows, summing column correctly
    @Test
    public void testCalculateColumnTotal_ValidColumn() {
        context.checking(new Expectations() {{
            allowing(values2D).getRowCount();
            will(returnValue(3));

            allowing(values2D).getValue(0, 0);
            will(returnValue(1.5));

            allowing(values2D).getValue(1, 0);
            will(returnValue(2.5));

            allowing(values2D).getValue(2, 0);
            will(returnValue(3.0));
        }});

        double result = DataUtilities.calculateColumnTotal(values2D, 0);
        assertEquals(7.0, result, 0.0001); // 1.5 + 2.5 + 3.0 = 7.0
    }

    Cover pairs: {1,2}, {1,4}, {3,13}, {4,5}
    // Test contains with no rows in Values2D (should return 0)
    @Test
    public void testCalculateColumnTotal_EmptyData() {
        context.checking(new Expectations() {{
            allowing(values2D).getRowCount();
            will(returnValue(0));
        }});

        double result = DataUtilities.calculateColumnTotal(values2D, 0);
        assertEquals(0.0, result, 0.0001); // No rows, so sum is 0
    }

    Cover pairs: {1,2}, {1,4}, {1,6}, {3,8}, {3,12}, {3,13}, {4,5}, {5,5}, {5,6}, {6,7}, {6,8}, {6,12}, {8,8}, {8,12}, {8,13}, {12,13}
    // Test contains handling null values in the column (should ignore nulls)
    @Test
    public void testCalculateColumnTotal_WithNullValues() {
        context.checking(new Expectations() {{
            allowing(values2D).getRowCount();
            will(returnValue(3));

            allowing(values2D).getValue(0, 0);
            will(returnValue(null)); // Should be ignored

            allowing(values2D).getValue(1, 0);
            will(returnValue(4.0));

            allowing(values2D).getValue(2, 0);
            will(returnValue(6.0));
        }});

        double result = DataUtilities.calculateColumnTotal(values2D, 0);
        assertEquals(10.0, result, 0.0001); // Null ignored, so 4.0 + 6.0 = 10.0
    }

    Cover pairs: {1,2}, {1,4}, {1,6}, {4,5},{5,5}, {5,6}
    // Test contains out-of-bounds column index (should throw IndexOutOfBoundsException)
    @Test(expected = IndexOutOfBoundsException.class)
    public void testCalculateColumnTotal_InvalidColumnIndex() {
        context.checking(new Expectations() {{
            allowing(values2D).getRowCount();
            will(returnValue(3));

            allowing(values2D).getValue(0, 5);
            will(throwException(new IndexOutOfBoundsException()));

            allowing(values2D).getValue(1, 5);
            will(throwException(new IndexOutOfBoundsException()));

            allowing(values2D).getValue(2, 5);
            will(throwException(new IndexOutOfBoundsException()));
        }});

        DataUtilities.calculateColumnTotal(values2D, 5);
    }

    Cover pairs: {1,2}, {1,4}, {1,6}, {4,5}, {5,5}, {5,6}, {3,5}, {3,8}, {6,7}, {6,8}, {7,8}
    // Test valid rows in range, summing selected rows in a column
    @Test
    public void testCalculateColumnTotal_ValidRowsInRange() {
        context.checking(new Expectations() {{
            allowing(values2D).getRowCount(); will(returnValue(3));
            allowing(values2D).getValue(0, 1); will(returnValue(1.0));
            allowing(values2D).getValue(2, 1); will(returnValue(4.0));
        }});

        int[] validRows = {0, 2}; // Only rows 0 and 2 included
        double result = DataUtilities.calculateColumnTotal(values2D, 1, validRows);
        assertEquals(5.0, result, 0.0001); // 1.0 + 4.0
    }

### Calculate the DU-Pair coverage.

DU-Pair Coverage = (Number of DU-pairs covered by tests/Total number of DU-pairs ) times 100% 
DU-Pair Coverage = 29/29=1 x 100% = 100%

## Method 2: Range.contains
![alt text](media/image-2.png)

###  Data flow graph

![alt text](media/image-4.png)

###  Def-use sets per statement

| Line | Code                                                                 | DU (Definition-Use) |
|------|----------------------------------------------------------------------|---------------------|
| 1    | public boolean contains(double value)                                | def={value} c-use={} p-use={} |
| 2    | if (value < this.lower)                                              | def={} c-use={} p-use={value, this.lower} |
| 3    | return false;                                                        | def={} c-use={} p-use={} |
| 4    | if (value > this.upper)                                              | def={} c-use={} p-use={value, this.upper} |
| 5    | return false;                                                        | def={} c-use={} p-use={} |
| 6    | return (value >= this.lower && value <= this.upper);                 | def={} c-use={value, this.lower, this.upper} p-use={} |

###  All DU-pairs per variable

| Variable | Def Line | Use Line          | DU Pair                                      |
|----------|----------|-------------------|----------------------------------------------|
| value    | 1        | 2, 4, 6           | {1,2}, {1,4}, {1,6}                          |
| this.lower | -      | 2, 6              | {-,2}, {-,6}                                 |
| this.upper | -      | 4, 6              | {-,4}, {-,6}                                 |

###  Each test case show which pairs are covered

    Cover pairs: {1,2}, {1,4}, {1,6}, {-,2}, {-,6}, {-,4}
    // Test contains with value within the range
    @Test
    public void testContains_ValueWithinRange() {
        Range range = new Range(1.0, 5.0);
        assertTrue(range.contains(3.0));
    }

    Cover pairs: {1,2}, {-,2}
    // Test contains with value outside the range (less than lower bound)
    @Test
    public void testContains_ValueOutsideRange_LessThanLower() {
        Range range = new Range(1.0, 5.0);
        assertFalse(range.contains(0.0));
    }

    Cover pairs: {1,2}, {1,4}, {-,2}, {-,4}
    // Test contains with value outside the range (greater than upper bound)
    @Test
    public void testContains_ValueOutsideRange_GreaterThanUpper() {
        Range range = new Range(1.0, 5.0);
        assertFalse(range.contains(6.0));
    }

### Calculate the DU-Pair coverage.

DU-Pair Coverage = (Number of DU-pairs covered by tests/Total number of DU-pairs ) times 100% 
DU-Pair Coverage = 7/7=1 x 100% = 100%

# 3 A detailed description of the testing strategy for the new unit test

**Isabelle:** The first step in our testing strategy was to run the coverage tools on the existing test cases from the previous lab to identify which areas required the most improvement. My initial focus was on writing unit tests for methods in the DataUtilities and Range classes that had not yet been tested. For DataUtilities, this included the clone(), equal(), and both variations of the calculateColumnTotal() and calculateRowTotal() methods. I designed new tests with the goal of achieving the target coverage thresholds by considering boundary conditions, branch decisions, and a variety of input partitions (both valid and invalid). Once the new test cases were completed, I revisited and refined the tests from the previous lab to help bring them closer to our ideal coverage goals.

**Kamand:** Some of the existing test cases were underperforming in terms of coverage, with statement (line) coverage being the most common issue. A notable example was the equals() method in the Range class, which initially only achieved 65% statement coverage despite testing most of its logic. The gap was due to untested scenarios involving invalid Range object comparisons, which accounted for roughly 30% of the method’s code. To address this, we modified the existing test case for equals() to explicitly handle invalid object inputs. This adjustment allowed us to reach 100% statement coverage for the method.

**Dylan:** The coverage tool was an essential part of our testing strategy. It played a key role in identifying missed branches and determining when additional test cases were needed. Since we were conducting white-box testing, it also helped us better understand the purpose and internal workings of various methods without having to rely solely on vague method descriptions. These insights significantly contributed to the development and improvement of our unit tests.

**Spiro:** My strategy involved thoroughly understanding each method individually before identifying the key test cases required for complete coverage. I worked method by method, carefully analyzing different paths and conditions to ensure robust testing. Throughout this process, EclEmma proved to be extremely helpful in visualizing code coverage and guiding us toward more effective testing practices.

# 4 A high level description of five selected test cases you have designed using coverage information, and how they have increased code coverage

Text…

# 5 A detailed report of the coverage achieved of each class and method (a screen shot from the code cover results in green and red color would suffice)

Line/Statement Coverage
![alt text](media/image-5.png)

![alt text](media/image-8.png)

Branch Coverage
![alt text](media/image-6.png)

![alt text](media/image-9.png)

Method Coverage
![alt text](media/image-7.png)

![alt text](media/image-10.png)

# 6 Pros and Cons of coverage tools used and Metrics you report

For our code coverage tool we chose to use EclEmma in Eclipse because it was the recommended tool as per the lab, as well as being very easy to integrate into our IDE, making it easy to use without much setup. It supports key coverage metrics like line, method, and branch coverage, which are sufficient for our project's needs. EclEmma provides real time feedback within the IDE, showing us which lines and branches are covered, which allows for immediate visibility and very easy analysis into the effectiveness of the tests we wrote. EclEmma does have some limitations, such as the lack of support for condition coverage (can be replaced with method coverage), which could have provided more detailed insights into the decision points in our code. Additionally, while the tool is lightweight and fast, it doesn't offer advanced customization or detailed reporting like some other tools do such as JaCoCo or Cobertura. Despite these drawbacks, we decided on using EclEmma due to its simplicity, ease of integration for Eclipse, and the fact that it met the basic coverage requirements for our project.

The suggested metrics to report from the lab were statement, branch, and condition coverages. Since we are using EclEmma, which does not support condition coverage, we opted to replace it with method coverage. This decision was made because method coverage still provides valuable insights into the effectiveness of testing by ensuring that each method in the code has been executed. While condition coverage maye have offered us a deeper analysis into decision points, method coverage serves as a practical substitution.

Pros: Simple integration with Eclipse, supports required coverage metrics (line, method (condition substitute), branch), gives real time in IDE feedback, lightweight and fast, free and open-source.
Cons: Lacks condition coverage, limited customization and reporting options, not as actively updated or feature-rich as other coverage tools like JaCoCo, only suitable for Java projects.


# 7 A comparison on the advantages and disadvantages of requirements-based test generation and coverage-based test generation.

Some advantages of requirements based test generation is that it ensures that all specified requirements of the system are tested, which helps in validating that the software is meeting needs and expectations of the user/client. Requirement based testing can uncover missing or ambiguous requirements by going through them each individually.

Disadvantages of coverage based testing is that it may result in execution paths or edge cases being missed by the testing, as there may be multiple paths that cover the same requirements and thus not all for them need to be tested.
For a complex system it can be really time consuming to create comprehensive tests for all requirements and it can be easy to miss some in a sizeable system. Requiring based on system requirements can not reveal defects that are not directly related to the specified requirements.

Coverage based test generation has many advantages as well. This technique makes sure that a high percentage of the code is executed during testing and can uncover defects in parts of the code that are not covered in requirements based tests. Coverage based testing can allow developers to identify dead code and untested paths/unused variables.

Disadvantages of coverage based testing is that it can result in tests that do not reflect real-world usage or requirements, for example it could be skipping an important/relevant requirement that is only a small portion of the code. It can also be very difficult to achieve 100% coverage, especially for complex codebases or very large projects. A high coverage percentage does not ensure that you can be confident in test quality, thus coverage based testing can lead to a false sense of security if high coverage is achieved but important requirements are not tested.

Overall, due to their own advantages and disadvantages, it is good to use both requirements based testing and coverage based testing together to achieve overall confidence in testing of your projects. 

# 8 A discussion on how the team work/effort was divided and managed

**Isabelle:** I focused on writing new test cases and enhancing existing ones for several methods in both DataUtilities and Range. Specifically, I worked on calculateColumnTotal(Values2D data, int column), calculateColumnTotal(Values2D data, int column, int[] validRows), calculateRowTotal(Values2D data, int row), calculateRowTotal(Values2D data, int row, int[] validCols), getLength(), getCentralValue(), min(), and max(). Additionally, I created the Data Flow Diagram (DFD), derived the def-use pairs, and manually calculated the coverage metrics for calculateColumnTotal(Values2D data, int column).

**Kamand:** I worked on enhancing previous test cases and writing new ones for key methods. In DataUtilities, I focused on getCumulativePercentages, and in the Range class, I contributed to testing combine, combineIgnoringNaN, scale, Range, and hashCode. I also performed the manual data flow coverage analysis for the getLength() method in the Range class.

**Dylan:**  My contributions involved both improving existing tests and developing new ones. In DataUtilities, I focused on the clone() and equal() methods. For the Range class, I worked on tests for equals, constrain, intersects, contains, getLowerBound(), and getUpperBound().

**Spiro:** I worked on enhancing and creating new test cases for the following methods: in DataUtilities, createNumberArray() and createNumberArray2D(), and in the Range class, toString(), expandToInclude(), isNaNRange(), shift(), and shiftWithNoZeroCrossing().

**Team Collaboration:** Although we divided the workload by assigning specific methods and classes to each team member, we maintained a collaborative approach through pair programming and regular code reviews. This allowed us to cross-check each other’s work, ensure consistency in testing practices, and collectively refine our test suite for optimal coverage and quality.

# 9 Any difficulties encountered, challenges overcome, and lessons learned from performing the lab

One of the difficulties that we encountered was figuring out how to view different metrics in EclEmma. Initially, we struggled to find the settings and options to display various coverage metrics such as line, branch, and method coverage. We spent some time exploring the tool and using online resources to understand how to configure EclEmma to show the desired metrics. Once we got past that, the tool was very intuitive to use. Similarly we had some problems using other coverage tools which is why we ended up using EclEmma as we found it the easiest to use and it was very simple to download and use in Eclipse which helped us save time trying to figure out other tools.

Additionally, we faced some challenges in achieving high coverage for complex methods with multiple branches and conditions. We used white-box testing techniques to design more effective tests and improve coverage. This process helped us gain a deeper understanding of the code and identify areas that required more thorough testing.


# 10 Comments/feedback on the lab itself

This lab assignment provided valuable insights into the importance of code coverage and the use of coverage tools (such as EclEmma) in software testing. We learned how to effectively use EclEmma to measure and improve our test coverage, and the experience highlighted the need for continuous learning and adaptation in software development. It also helped us compare and see the differences of requirement based and coverage based test generation and further consider their advantages and consequences. We liked that we were able to build this lab off of the existing assignment work and tests we had created for the previous lab as it got rid of some of the time usually spent on understanding the test environment and setup which takes a while. We found the lab instructions however were a bit misleading. Some points (especially regarding the use of coverage tools) were hard to follow and it was unclear what the expectations of us were and how many tools were required to be used. We found this confusion in other sections as well.
